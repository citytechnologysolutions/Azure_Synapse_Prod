{
	"name": "SST_RunOrder",
	"properties": {
		"folder": {
			"name": "TRANSFORM/01 SEMI-STRUCTURED"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "TESTSparkPoolL",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "56g",
			"driverCores": 8,
			"executorMemory": "56g",
			"executorCores": 8,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "true",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "8",
				"spark.autotune.trackingId": "8dbce8cf-cae1-4af1-839b-ab80bd096433"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": true,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/99b4fa8b-7705-4d41-a2fb-4f8f9ee006c7/resourceGroups/AZ_Resource_DataWarehouse_Prod/providers/Microsoft.Synapse/workspaces/citylogistics-synapseanalytics-workspace-prod/bigDataPools/TESTSparkPoolL",
				"name": "TESTSparkPoolL",
				"type": "Spark",
				"endpoint": "https://citylogistics-synapseanalytics-workspace-prod.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/TESTSparkPoolL",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.3",
				"nodeCount": 10,
				"cores": 16,
				"memory": 112,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 1
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"Environment = mssparkutils.env.getWorkspaceName()\r\n",
					"if 'prod' in Environment:\r\n",
					"    StorageAccount = 'citylogisticsstorageprod'\r\n",
					"    StorageAccountRead = 'citylogisticsstorageprod'\r\n",
					"    StorageAccountRead2 = 'citylogisticsstorageprod'\r\n",
					"    StorageAccountWrite = 'citylogisticsstorageprod'\r\n",
					"else:\r\n",
					"    StorageAccount = 'citylogisticsstorage'\r\n",
					"    StorageAccountRead = 'citylogisticsstorageprod'\r\n",
					"    StorageAccountRead2 = 'citylogisticsstorage'\r\n",
					"    StorageAccountWrite = 'citylogisticsstorage'\r\n",
					"\r\n",
					"# ' + StorageAccount + '"
				],
				"execution_count": 8
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"**<mark>RUN UNION NOTEBOOKS</mark>**"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#Create DataFrame for the dboconsignment_archive LMS Table\r\n",
					"dboconsignment_archive = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dboconsignment_archive.parquet', format='parquet')\r\n",
					"dboconsignment_archive.createOrReplaceTempView(\"dboconsignment_archive\")\r\n",
					"\r\n",
					"#Create DataFrame for the dboconsignment LMS Table\r\n",
					"dboconsignment = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dboconsignment.parquet', format='parquet')\r\n",
					"dboconsignment.createOrReplaceTempView(\"dboconsignment\")"
				],
				"execution_count": 9
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"%run TRANSFORM/01 SEMI-STRUCTURED/01_LMS Union/SSTConsignmentUnion"
				],
				"execution_count": 10
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"sstconsignmentunion.write.parquet('abfss://synapse@' + StorageAccountWrite + '.dfs.core.windows.net/Semi Structured Data/OPS/sstconsignmentunion.parquet', mode = \"overwrite\")"
				],
				"execution_count": 11
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#Create DataFrame for the dboparcel_archive LMS Table\r\n",
					"dboparcel_archive = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dboparcel_archive.parquet', format='parquet')\r\n",
					"dboparcel_archive.createOrReplaceTempView(\"dboparcel_archive\")\r\n",
					"\r\n",
					"#Create DataFrame for the dboparcel LMS Table\r\n",
					"dboparcel = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dboparcel.parquet', format='parquet')\r\n",
					"dboparcel.createOrReplaceTempView(\"dboparcel\")\r\n",
					"\r\n",
					"#Create DataFrame for the dboorder LMS Table\r\n",
					"dboorder = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dboorder.parquet', format='parquet')\r\n",
					"dboorder.createOrReplaceTempView(\"dboorder\")"
				],
				"execution_count": 12
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"%run TRANSFORM/01 SEMI-STRUCTURED/01_LMS Union/SSTParcelUnion"
				],
				"execution_count": 13
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"sstparcelunion.write.parquet('abfss://synapse@' + StorageAccountWrite + '.dfs.core.windows.net/Semi Structured Data/OPS/sstparcelunion.parquet', mode = \"overwrite\")"
				],
				"execution_count": 14
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#Create DataFrame for the dbotrack_archive LMS Table\r\n",
					"dbotrack_archive = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbotrack_archive.parquet', format='parquet')\r\n",
					"dbotrack_archive.createOrReplaceTempView(\"dbotrack_archive\")\r\n",
					"\r\n",
					"#Create DataFrame for the dbotrack LMS Table\r\n",
					"dbotrack = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbotrack.parquet', format='parquet')\r\n",
					"dbotrack.createOrReplaceTempView(\"dbotrack\")\r\n",
					"\r\n",
					"#Create DataFrame for the sstparcelunion LMS Table\r\n",
					"sstparcelunion = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Semi Structured Data/OPS/sstparcelunion.parquet', format='parquet')\r\n",
					"sstparcelunion.createOrReplaceTempView(\"sstparcelunion\")\r\n",
					""
				],
				"execution_count": 15
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"%run TRANSFORM/01 SEMI-STRUCTURED/01_LMS Union/SSTTrackUnion"
				],
				"execution_count": 16
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"ssttrackunion.write.parquet('abfss://synapse@' + StorageAccountWrite + '.dfs.core.windows.net/Semi Structured Data/OPS/ssttrackunion.parquet', mode = \"overwrite\")"
				],
				"execution_count": 17
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#Create DataFrame for the sstparcelunion LMS Table\r\n",
					"sstparcelunion = spark.read.load('abfss://synapse@' + StorageAccountRead2 + '.dfs.core.windows.net/Semi Structured Data/OPS/sstparcelunion.parquet', format='parquet')\r\n",
					"sstparcelunion.createOrReplaceTempView(\"sstparcelunion\")\r\n",
					"\r\n",
					"#Create DataFrame for the ssttrackunion LMS Table\r\n",
					"ssttrackunion = spark.read.load('abfss://synapse@' + StorageAccountRead2 + '.dfs.core.windows.net/Semi Structured Data/OPS/ssttrackunion.parquet', format='parquet')\r\n",
					"ssttrackunion.createOrReplaceTempView(\"ssttrackunion\")\r\n",
					"\r\n",
					"#Create DataFrame for the dbowaybillsperparcel LMS Table\r\n",
					"dbowaybillsperparcel = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbowaybillsperparcel.parquet', format='parquet')\r\n",
					"dbowaybillsperparcel.createOrReplaceTempView(\"dbowaybillsperparcel\")\r\n",
					"\r\n",
					"#Create DataFrame for the dbowaybill LMS Table\r\n",
					"dbowaybill = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbowaybill.parquet', format='parquet')\r\n",
					"dbowaybill.createOrReplaceTempView(\"dbowaybill\")\r\n",
					""
				],
				"execution_count": 18
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"%run TRANSFORM/01 SEMI-STRUCTURED/01_LMS Union/SSTWaybilsPerParcel"
				],
				"execution_count": 19
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"sstwaybillsperparcel.write.parquet('abfss://synapse@' + StorageAccountWrite + '.dfs.core.windows.net/Semi Structured Data/OPS/sstwaybillsperparcel.parquet', mode = \"overwrite\")"
				],
				"execution_count": 20
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"**<mark>RUN AGGR NOTEBOOKS</mark>**"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Create SSTParcelByOrder \r\n",
					"# Create SSTParcelByWaybill\r\n",
					"# Create SSTParcelByConsignment\r\n",
					"# Create SSTParcelByLoad\r\n",
					"\r\n",
					"# IN DEV StorageAccountRead = StorageAccountWrite for sstparcelunion and ssttrackunion as these are writing to dev\r\n",
					"\r\n",
					"#Create DataFrame for the sstparcelunion LMS Table\r\n",
					"sstparcelunion = spark.read.load('abfss://synapse@' + StorageAccountRead2 + '.dfs.core.windows.net/Semi Structured Data/OPS/sstparcelunion.parquet', format='parquet')\r\n",
					"sstparcelunion.createOrReplaceTempView(\"sstparcelunion\")\r\n",
					"\r\n",
					"#Create DataFrame for the ssttrackunion LMS Table\r\n",
					"ssttrackunion = spark.read.load('abfss://synapse@' + StorageAccountRead2 + '.dfs.core.windows.net/Semi Structured Data/OPS/ssttrackunion.parquet', format='parquet')\r\n",
					"ssttrackunion.createOrReplaceTempView(\"ssttrackunion\")\r\n",
					"\r\n",
					"#Create DataFrame for the dboorder LMS Table\r\n",
					"dboorder = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dboorder.parquet', format='parquet')\r\n",
					"dboorder.createOrReplaceTempView(\"dboorder\")"
				],
				"execution_count": 21
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"%run TRANSFORM/01 SEMI-STRUCTURED/02_LMS Aggr/SSTAggrParcelByX"
				],
				"execution_count": 22
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"sstparcelbyorder.write.parquet('abfss://synapse@' + StorageAccountWrite + '.dfs.core.windows.net/Semi Structured Data/OPS/sstparcelbyorder.parquet', mode = \"overwrite\")\r\n",
					"sstparcelbywaybill.write.parquet('abfss://synapse@' + StorageAccountWrite + '.dfs.core.windows.net/Semi Structured Data/OPS/sstparcelbywaybill.parquet', mode = \"overwrite\")\r\n",
					"sstparcelbyconsignment.write.parquet('abfss://synapse@' + StorageAccountWrite + '.dfs.core.windows.net/Semi Structured Data/OPS/sstparcelbyconsignment.parquet', mode = \"overwrite\")\r\n",
					"sstparcelbyload.write.parquet('abfss://synapse@' + StorageAccountWrite + '.dfs.core.windows.net/Semi Structured Data/OPS/sstparcelbyload.parquet', mode = \"overwrite\")"
				],
				"execution_count": 23
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"**<mark>RUN LMS+ORV NOTEBOOKS</mark>**"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# #Create DataFrame for the dbocollect LMS Table\r\n",
					"# dbocollect = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbocollect.parquet', format='parquet')\r\n",
					"# dbocollect.createOrReplaceTempView(\"dbocollect\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dbocustomer LMS Table\r\n",
					"# dbocustomer = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbocustomer.parquet', format='parquet')\r\n",
					"# dbocustomer.createOrReplaceTempView(\"dbocustomer\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dbousers LMS Table\r\n",
					"# dbousers = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbousers.parquet', format='parquet')\r\n",
					"# dbousers.createOrReplaceTempView(\"dbousers\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dbolocation LMS Table\r\n",
					"# dbolocation= spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbolocation.parquet', format='parquet')\r\n",
					"# dbolocation.createOrReplaceTempView(\"dbolocation\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dbodb_collectstatus LMS Table\r\n",
					"# dbodb_collectstatus = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbodb_collectstatus.parquet', format='parquet')\r\n",
					"# dbodb_collectstatus.createOrReplaceTempView(\"dbodb_collectstatus\")\r\n",
					"\r\n",
					"# #Create DataFrame for the publicdraftcollection ORV Table\r\n",
					"# publicdraftcollection = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/Onroute/publicdraftcollection.parquet', format='parquet')\r\n",
					"# publicdraftcollection.createOrReplaceTempView(\"publicdraftcollection\")\r\n",
					"\r\n",
					"# #Create DataFrame for the publicdelivery ORV Table\r\n",
					"# publicdelivery = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/Onroute/publicdelivery.parquet', format='parquet')\r\n",
					"# publicdelivery.createOrReplaceTempView(\"publicdelivery\")\r\n",
					"\r\n",
					"# #Create DataFrame for the publicmall ORV Table\r\n",
					"# publicmall = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/Onroute/publicmall.parquet', format='parquet')\r\n",
					"# publicmall.createOrReplaceTempView(\"publicmall\")\r\n",
					"\r\n",
					"# #Create DataFrame for the publiccustomer ORV Table\r\n",
					"# publiccustomer = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/Onroute/publiccustomer.parquet', format='parquet')\r\n",
					"# publiccustomer.createOrReplaceTempView(\"publiccustomer\")\r\n",
					""
				],
				"execution_count": 24
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# %run TRANSFORM/01 SEMI-STRUCTURED/03_LMS + ORV/SSTCollect"
				],
				"execution_count": 25
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# sstcollect.write.parquet('abfss://synapse@' + StorageAccountWrite + '.dfs.core.windows.net/Semi Structured Data/OPS/sstcollect.parquet', mode = \"overwrite\")"
				],
				"execution_count": 26
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# #Create DataFrame for the ssttrackunion LMS Table\r\n",
					"# ssttrackunion = spark.read.load('abfss://synapse@' + StorageAccountRead2 + '.dfs.core.windows.net/Semi Structured Data/OPS/ssttrackunion.parquet', format='parquet')\r\n",
					"# ssttrackunion.createOrReplaceTempView(\"ssttrackunion\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dbolocation LMS Table\r\n",
					"# dbolocation= spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbolocation.parquet', format='parquet')\r\n",
					"# dbolocation.createOrReplaceTempView(\"dbolocation\")"
				],
				"execution_count": 27
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# %run TRANSFORM/01 SEMI-STRUCTURED/03_LMS + ORV/SSTTrack"
				],
				"execution_count": 28
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# ssttrack.write.parquet('abfss://synapse@' + StorageAccountWrite + '.dfs.core.windows.net/Semi Structured Data/OPS/ssttrack.parquet', mode = \"overwrite\")"
				],
				"execution_count": 29
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# #Create DataFrame for the sstconsignmentunion LMS Table\r\n",
					"# sstconsignmentunion = spark.read.load('abfss://synapse@' + StorageAccountRead2 + '.dfs.core.windows.net/Semi Structured Data/OPS/sstconsignmentunion.parquet', format='parquet')\r\n",
					"# sstconsignmentunion.createOrReplaceTempView(\"sstconsignmentunion\")\r\n",
					"\r\n",
					"# #Create DataFrame for the sstparcelbyconsignment LMS Table\r\n",
					"# sstparcelbyconsignment = spark.read.load('abfss://synapse@' + StorageAccountRead2 + '.dfs.core.windows.net/Semi Structured Data/OPS/sstparcelbyconsignment.parquet', format='parquet')\r\n",
					"# sstparcelbyconsignment.createOrReplaceTempView(\"sstparcelbyconsignment\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dbobill_consignmentr LMS Table\r\n",
					"# dbobill_consignmentr = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbobill_consignmentr.parquet', format='parquet')\r\n",
					"# dbobill_consignmentr.createOrReplaceTempView(\"dbobill_consignmentr\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dbousers LMS Table\r\n",
					"# dbousers = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbousers.parquet', format='parquet')\r\n",
					"# dbousers.createOrReplaceTempView(\"dbousers\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dbocustomer LMS Table\r\n",
					"# dbocustomer = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbocustomer.parquet', format='parquet')\r\n",
					"# dbocustomer.createOrReplaceTempView(\"dbocustomer\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dbobill_delivertype LMS Table\r\n",
					"# dbobill_delivertype = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbobill_delivertype.parquet', format='parquet')\r\n",
					"# dbobill_delivertype.createOrReplaceTempView(\"dbobill_delivertype\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dbobill_zone LMS Table\r\n",
					"# dbobill_zone = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbobill_zone.parquet', format='parquet')\r\n",
					"# dbobill_zone.createOrReplaceTempView(\"dbobill_zone\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dbobill_servicetype LMS Table\r\n",
					"# dbobill_servicetype = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbobill_servicetype.parquet', format='parquet')\r\n",
					"# dbobill_servicetype.createOrReplaceTempView(\"dbobill_servicetype\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dbobill_zoneroute LMS Table\r\n",
					"# dbobill_zoneroute = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbobill_zoneroute.parquet', format='parquet')\r\n",
					"# dbobill_zoneroute.createOrReplaceTempView(\"dbobill_zoneroute\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dbobill_billtypesr LMS Table\r\n",
					"# dbobill_billtypesr = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbobill_billtypesr.parquet', format='parquet')\r\n",
					"# dbobill_billtypesr.createOrReplaceTempView(\"dbobill_billtypesr\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dbobill_routerate LMS Table\r\n",
					"# dbobill_routerate = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbobill_routerate.parquet', format='parquet')\r\n",
					"# dbobill_routerate.createOrReplaceTempView(\"dbobill_routerate\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dbobroutemaster LMS Table\r\n",
					"# dbobroutemaster = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbobroutemaster.parquet', format='parquet')\r\n",
					"# dbobroutemaster.createOrReplaceTempView(\"dbobroutemaster\")"
				],
				"execution_count": 30
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# %run TRANSFORM/01 SEMI-STRUCTURED/03_LMS + ORV/SSTConsignment"
				],
				"execution_count": 31
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# sstconsignment.write.parquet('abfss://synapse@' + StorageAccountWrite + '.dfs.core.windows.net/Semi Structured Data/OPS/sstconsignment.parquet', mode = \"overwrite\")"
				],
				"execution_count": 32
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# #Create DataFrame for the dboloads LMS Table\r\n",
					"# dboloads = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dboloads.parquet', format='parquet')\r\n",
					"# dboloads.createOrReplaceTempView(\"dboloads\")\r\n",
					"\r\n",
					"# #Create DataFrame for the sstparcelbyload LMS Table\r\n",
					"# sstparcelbyload = spark.read.load('abfss://synapse@' + StorageAccountRead2 + '.dfs.core.windows.net/Semi Structured Data/OPS/sstparcelbyload.parquet', format='parquet')\r\n",
					"# sstparcelbyload.createOrReplaceTempView(\"sstparcelbyload\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dbosroute LMS Table\r\n",
					"# dbosroute = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbosroute.parquet', format='parquet')\r\n",
					"# dbosroute.createOrReplaceTempView(\"dbosroute\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dbodriver LMS Table\r\n",
					"# dbodriver = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbodriver.parquet', format='parquet')\r\n",
					"# dbodriver.createOrReplaceTempView(\"dbodriver\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dbovehicle LMS Table\r\n",
					"# dbovehicle = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbovehicle.parquet', format='parquet')\r\n",
					"# dbovehicle.createOrReplaceTempView(\"dbovehicle\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dbovehiclebasic LMS Table\r\n",
					"# dbovehiclebasic = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/CLMasterData/dbovehiclebasic.parquet', format='parquet')\r\n",
					"# dbovehiclebasic.createOrReplaceTempView(\"dbovehiclebasic\")\r\n",
					""
				],
				"execution_count": 33
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# %run TRANSFORM/01 SEMI-STRUCTURED/03_LMS + ORV/SSTLoadChild"
				],
				"execution_count": 34
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# sstloadchild.write.parquet('abfss://synapse@' + StorageAccountWrite + '.dfs.core.windows.net/Semi Structured Data/OPS/sstloadchild.parquet', mode = \"overwrite\")"
				],
				"execution_count": 35
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# #Create DataFrame for the sstloadchild LMS Table\r\n",
					"# sstloadchild = spark.read.load('abfss://synapse@' + StorageAccountRead2 + '.dfs.core.windows.net/Semi Structured Data/OPS/sstloadchild.parquet', format='parquet')\r\n",
					"# sstloadchild.createOrReplaceTempView(\"sstloadchild\")\r\n",
					"\r\n",
					"# #Create DataFrame for the publicdispatch ORV Table\r\n",
					"# publicdispatch = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/Onroute/publicdispatch.parquet', format='parquet')\r\n",
					"# publicdispatch.createOrReplaceTempView(\"publicdispatch\")\r\n",
					"\r\n",
					"# #Create DataFrame for the publicvehicle ORV Table\r\n",
					"# publicvehicle = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/Onroute/publicvehicle.parquet', format='parquet')\r\n",
					"# publicvehicle.createOrReplaceTempView(\"publicvehicle\")\r\n",
					"\r\n",
					"# #Create DataFrame for the publicorvuser ORV Table\r\n",
					"# publicorvuser = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/Onroute/publicorvuser.parquet', format='parquet')\r\n",
					"# publicorvuser.createOrReplaceTempView(\"publicorvuser\")"
				],
				"execution_count": 36
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# %run TRANSFORM/01 SEMI-STRUCTURED/03_LMS + ORV/SSTLoadParent"
				],
				"execution_count": 37
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# sstloadparent.write.parquet('abfss://synapse@' + StorageAccountWrite + '.dfs.core.windows.net/Semi Structured Data/OPS/sstloadparent.parquet', mode = \"overwrite\")"
				],
				"execution_count": 38
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# #Create DataFrame for the dboorder LMS Table\r\n",
					"# dboorder = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dboorder.parquet', format='parquet')\r\n",
					"# dboorder.createOrReplaceTempView(\"dboorder\")\r\n",
					"\r\n",
					"# #Create DataFrame for the sstparcelbyorder LMS Table\r\n",
					"# sstparcelbyorder = spark.read.load('abfss://synapse@' + StorageAccountRead2 + '.dfs.core.windows.net/Semi Structured Data/OPS/sstparcelbyorder.parquet', format='parquet')\r\n",
					"# sstparcelbyorder.createOrReplaceTempView(\"sstparcelbyorder\")"
				],
				"execution_count": 39
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# %run TRANSFORM/01 SEMI-STRUCTURED/03_LMS + ORV/SSTOrder"
				],
				"execution_count": 40
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# sstorder.write.parquet('abfss://synapse@' + StorageAccountWrite + '.dfs.core.windows.net/Semi Structured Data/OPS/sstorder.parquet', mode = \"overwrite\")"
				],
				"execution_count": 41
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# #Create DataFrame for the dboparcel LMS Table\r\n",
					"# dboparcel = spark.read.load('abfss://synapse@' + StorageAccountRead2 + '.dfs.core.windows.net/Semi Structured Data/OPS/sstparcelunion.parquet', format='parquet')\r\n",
					"# dboparcel.createOrReplaceTempView(\"dboparcel\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dbowaybill LMS Table\r\n",
					"# dbowaybill = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbowaybill.parquet', format='parquet')\r\n",
					"# dbowaybill.createOrReplaceTempView(\"dbowaybill\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dboorder LMS Table\r\n",
					"# dboorder = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dboorder.parquet', format='parquet')\r\n",
					"# dboorder.createOrReplaceTempView(\"dboorder\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dboconsignment LMS Table\r\n",
					"# dboconsignment = spark.read.load('abfss://synapse@' + StorageAccountRead2 + '.dfs.core.windows.net/Semi Structured Data/OPS/sstconsignmentunion.parquet', format='parquet')\r\n",
					"# dboconsignment.createOrReplaceTempView(\"dboconsignment\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dboparceldetail LMS Table\r\n",
					"# dboparceldetail = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dboparceldetail.parquet', format='parquet')\r\n",
					"# dboparceldetail.createOrReplaceTempView(\"dboparceldetail\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dbocustomer LMS Table\r\n",
					"# dbocustomer = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbocustomer.parquet', format='parquet')\r\n",
					"# dbocustomer.createOrReplaceTempView(\"dbocustomer\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dbousers LMS Table\r\n",
					"# dbousers = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbousers.parquet', format='parquet')\r\n",
					"# dbousers.createOrReplaceTempView(\"dbousers\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dbobill_parceltype LMS Table\r\n",
					"# dbobill_parceltype = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbobill_parceltype.parquet', format='parquet')\r\n",
					"# dbobill_parceltype.createOrReplaceTempView(\"dbobill_parceltype\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dbolocation LMS Table\r\n",
					"# dbolocation= spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbolocation.parquet', format='parquet')\r\n",
					"# dbolocation.createOrReplaceTempView(\"dbolocation\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dbodstatus LMS Table\r\n",
					"# dbodstatus = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbodstatus.parquet', format='parquet')\r\n",
					"# dbodstatus.createOrReplaceTempView(\"dbodstatus\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dbovolumiser LMS Table\r\n",
					"# dbovolumiser = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbovolumiser.parquet', format='parquet')\r\n",
					"# dbovolumiser.createOrReplaceTempView(\"dbovolumiser\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dbobill_parceltype LMS Table\r\n",
					"# dbobill_parceltype = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbobill_parceltype.parquet', format='parquet')\r\n",
					"# dbobill_parceltype.createOrReplaceTempView(\"dbobill_parceltype\")\r\n",
					"\r\n",
					"# #Create DataFrame for the publicparcel ORV Table\r\n",
					"# publicparcel = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/Onroute/publicparcel.parquet', format='parquet')\r\n",
					"# publicparcel.createOrReplaceTempView(\"publicparcel\")\r\n",
					"\r\n",
					"# #Create DataFrame for the publicdelivery ORV Table\r\n",
					"# publicdelivery = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/Onroute/publicdelivery.parquet', format='parquet')\r\n",
					"# publicdelivery.createOrReplaceTempView(\"publicdelivery\")"
				],
				"execution_count": 42
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# %run TRANSFORM/01 SEMI-STRUCTURED/03_LMS + ORV/SSTParcel"
				],
				"execution_count": 43
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# sstparcel.write.parquet('abfss://synapse@' + StorageAccountWrite + '.dfs.core.windows.net/Semi Structured Data/OPS/sstparcel.parquet', mode = \"overwrite\")"
				],
				"execution_count": 44
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# #Create DataFrame for the dbowaybill LMS Table\r\n",
					"# dbowaybill = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbowaybill.parquet', format='parquet')\r\n",
					"# dbowaybill.createOrReplaceTempView(\"dbowaybill\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dbocustomer LMS Table\r\n",
					"# dbocustomer = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbocustomer.parquet', format='parquet')\r\n",
					"# dbocustomer.createOrReplaceTempView(\"dbocustomer\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dbousers LMS Table\r\n",
					"# dbousers = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbousers.parquet', format='parquet')\r\n",
					"# dbousers.createOrReplaceTempView(\"dbousers\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dbodb_delayreason LMS Table\r\n",
					"# dbodb_delayreason = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbodb_delayreason.parquet', format='parquet')\r\n",
					"# dbodb_delayreason.createOrReplaceTempView(\"dbodb_delayreason\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dbodb_reasondetail LMS Table\r\n",
					"# dbodb_reasondetail = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbodb_reasondetail.parquet', format='parquet')\r\n",
					"# dbodb_reasondetail.createOrReplaceTempView(\"dbodb_reasondetail\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dbodb_reasongroup LMS Table\r\n",
					"# dbodb_reasongroup = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbodb_reasongroup.parquet', format='parquet')\r\n",
					"# dbodb_reasongroup.createOrReplaceTempView(\"dbodb_reasongroup\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dbodb_deliverystatus LMS Table\r\n",
					"# dbodb_deliverystatus = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbodb_deliverystatus.parquet', format='parquet')\r\n",
					"# dbodb_deliverystatus.createOrReplaceTempView(\"dbodb_deliverystatus\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dbodb_mobilefeedbackreason LMS Table\r\n",
					"# dbodb_mobilefeedbackreason = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbodb_mobilefeedbackreason.parquet', format='parquet')\r\n",
					"# dbodb_mobilefeedbackreason.createOrReplaceTempView(\"dbodb_mobilefeedbackreason\")\r\n",
					"\r\n",
					"# #Create DataFrame for the publicdelivery ORV Table\r\n",
					"# publicdelivery = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/Onroute/publicdelivery.parquet', format='parquet')\r\n",
					"# publicdelivery.createOrReplaceTempView(\"publicdelivery\")\r\n",
					"\r\n",
					"# #Create DataFrame for the publicmall ORV Table\r\n",
					"# publicmall = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/Onroute/publicmall.parquet', format='parquet')\r\n",
					"# publicmall.createOrReplaceTempView(\"publicmall\")\r\n",
					"\r\n",
					"# #Create DataFrame for the publiccustomer ORV Table\r\n",
					"# publiccustomer = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/Onroute/publiccustomer.parquet', format='parquet')\r\n",
					"# publiccustomer.createOrReplaceTempView(\"publiccustomer\")\r\n",
					"\r\n",
					"# #Create DataFrame for the sstparcelbywaybill LMS Table\r\n",
					"# sstparcelbywaybill = spark.read.load('abfss://synapse@' + StorageAccountRead2 + '.dfs.core.windows.net/Semi Structured Data/OPS/sstparcelbywaybill.parquet', format='parquet')\r\n",
					"# sstparcelbywaybill.createOrReplaceTempView(\"sstparcelbywaybill\")"
				],
				"execution_count": 45
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# %run TRANSFORM/01 SEMI-STRUCTURED/03_LMS + ORV/SSTWaybill"
				],
				"execution_count": 46
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# sstwaybill.write.parquet('abfss://synapse@' + StorageAccountWrite + '.dfs.core.windows.net/Semi Structured Data/OPS/sstwaybill.parquet', mode = \"overwrite\")"
				],
				"execution_count": 47
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# #Create DataFrame for the ssttrackunion LMS Table\r\n",
					"# ssttrackunion = spark.read.load('abfss://synapse@' + StorageAccountRead2 + '.dfs.core.windows.net/Semi Structured Data/OPS/ssttrackunion.parquet', format='parquet')\r\n",
					"# ssttrackunion.createOrReplaceTempView(\"ssttrackunion\")\r\n",
					"\r\n",
					"# #Create DataFrame for the dbowaybillsperparcel LMS Table\r\n",
					"# dbowaybillsperparcel = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/LMS/dbowaybillsperparcel.parquet', format='parquet')\r\n",
					"# dbowaybillsperparcel.createOrReplaceTempView(\"dbowaybillsperparcel\")\r\n",
					""
				],
				"execution_count": 48
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# %run TRANSFORM/01 SEMI-STRUCTURED/03_LMS + ORV/SSTWaybilsPerParcel"
				],
				"execution_count": 49
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# sstwaybillsperparcel.write.parquet('abfss://synapse@' + StorageAccountWrite + '.dfs.core.windows.net/Semi Structured Data/OPS/sstwaybillsperparcel.parquet', mode = \"overwrite\")"
				],
				"execution_count": 50
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# #Create DataFrame for the publicnonbooking TMS Table\r\n",
					"# publicnonbooking = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/TMS/publicnonbooking.parquet', format='parquet')\r\n",
					"# publicnonbooking.createOrReplaceTempView(\"publicnonbooking\")\r\n",
					"\r\n",
					"# #Create DataFrame for the publicbooking TMS Table\r\n",
					"# publicbooking = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/TMS/publicbooking.parquet', format='parquet')\r\n",
					"# publicbooking.createOrReplaceTempView(\"publicbooking\")\r\n",
					"\r\n",
					"# #Create DataFrame for the publiccustomer TMS Table\r\n",
					"# publiccustomer = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/TMS/publiccustomer.parquet', format='parquet')\r\n",
					"# publiccustomer.createOrReplaceTempView(\"publiccustomer\")\r\n",
					"\r\n",
					"# #Create DataFrame for the publicroute TMS Table\r\n",
					"# publicroute = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/TMS/publicroute.parquet', format='parquet')\r\n",
					"# publicroute.createOrReplaceTempView(\"publicroute\")\r\n",
					"\r\n",
					"# #Create DataFrame for the publicthirdparty TMS Table\r\n",
					"# publicthirdparty = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/TMS/publicthirdparty.parquet', format='parquet')\r\n",
					"# publicthirdparty.createOrReplaceTempView(\"publicthirdparty\")\r\n",
					"\r\n",
					"# #Create DataFrame for the publicfinancedata TMS Table\r\n",
					"# publicfinancedata = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/TMS/publicfinancedata.parquet', format='parquet')\r\n",
					"# publicfinancedata.createOrReplaceTempView(\"publicfinancedata\")\r\n",
					""
				],
				"execution_count": 51
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# %run TRANSFORM/01 SEMI-STRUCTURED/04_TMS + ORV/SSTBooking"
				],
				"execution_count": 52
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# sstbooking.write.parquet('abfss://synapse@' + StorageAccountWrite + '.dfs.core.windows.net/Semi Structured Data/OPS/sstbooking.parquet', mode = \"overwrite\")"
				],
				"execution_count": 53
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# #Create DataFrame for the publicinstruction TMS Table\r\n",
					"# publicinstruction = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/TMS/publicinstruction.parquet', format='parquet')\r\n",
					"# publicinstruction.createOrReplaceTempView(\"publicinstruction\")\r\n",
					"\r\n",
					"# #Create DataFrame for the publicaddress TMS Table\r\n",
					"# publicaddress = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/TMS/publicaddress.parquet', format='parquet')\r\n",
					"# publicaddress.createOrReplaceTempView(\"publicaddress\")\r\n",
					"\r\n",
					"# #Create DataFrame for the publiclhdelivery ORV Table\r\n",
					"# publiclhdelivery = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/Onroute/publiclhdelivery.parquet', format='parquet')\r\n",
					"# publiclhdelivery.createOrReplaceTempView(\"publiclhdelivery\")"
				],
				"execution_count": 54
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# %run TRANSFORM/01 SEMI-STRUCTURED/04_TMS + ORV/SSTInstruction"
				],
				"execution_count": 55
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# sstinstruction.write.parquet('abfss://synapse@' + StorageAccountWrite + '.dfs.core.windows.net/Semi Structured Data/OPS/sstinstruction.parquet', mode = \"overwrite\")"
				],
				"execution_count": 56
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# #Create DataFrame for the publictrip TMS Table\r\n",
					"# publictrip = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/TMS/publictrip.parquet', format='parquet')\r\n",
					"# publictrip.createOrReplaceTempView(\"publictrip\")\r\n",
					"\r\n",
					"# #Create DataFrame for the publicdriverpayitem TMS Table\r\n",
					"# publicdriverpayitem = spark.read.load('abfss://synapse@' + StorageAccountRead + '.dfs.core.windows.net/Unstructured Data/TMS/publicdriverpayitem.parquet', format='parquet')\r\n",
					"# publicdriverpayitem.createOrReplaceTempView(\"publicdriverpayitem\")"
				],
				"execution_count": 57
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# %run TRANSFORM/01 SEMI-STRUCTURED/04_TMS + ORV/SSTTrip"
				],
				"execution_count": 58
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# ssttrip.write.parquet('abfss://synapse@' + StorageAccountWrite + '.dfs.core.windows.net/Semi Structured Data/OPS/ssttrip.parquet', mode = \"overwrite\")"
				],
				"execution_count": 59
			}
		]
	}
}